# 本

- 組み合わせ最適化-メタ戦略を中心として-
- 柳浦睦憲 / 茨木俊秀
- 朝倉書店

# 1 章 : 組み合わせ最適化問題

## 組み合わせ最適化問題の一般的な定義

- 基本的な最適化問題の表現

$$
\begin{aligned}
	最小化 \:\: & f(x)\\
	制約条件 \:\: & x \in F
\end{aligned}
$$

- $f$ : 目的関数
	- 現実に存在してほしいので、$f(x)$は実数値か整数値をとる
- $F$ : 実行可能領域
- ちなみに
	- $x \in F$ なら実行可能解
	- $x \not \in F$なら実行不可能解
- 組み合わせ最適化問題の目的
	- $f(x)$を最小にする$x$(=最適解)を求めること
- 大局的最適解と局所的最適解
	- 大局的最適解
		- 実行可能領域$F$全域における最適解
	- 局所的最適解
		- $F$の一部における最適解

## 有名な例

### 巡回セールスマン問題

- Traveling Salesman Problem(TSP)
- 一番有名なやつ
- 1 人のセールスマンが営業先を 10 個回らないといけないんだけど、最短経路はどれ？という問題
- 定式化して入力と出力を書くと次のようになる

$$
\begin{aligned}
	入力1 &: n個の訪問先集合V={1,\cdots,n}\\
	入力2 &: 訪問先iと訪問先jの間の距離d_{i,j} (i,j \in V)\\
	出力 &: 総距離 f_{TSP}(\sigma) = \sum_{k=1}^{n-1}d_{\sigma(k),\sigma(k+1)} + d_{\sigma(n),\sigma(1)}を最小にする巡回路\sigma
\end{aligned}
$$

- 計算量

	- 最悪計算量は$O(N!)$
		- 訪問先の順列を列挙すればよいため

- 種類
	- 対称 TSP
		- 全ての$i$に対し、$d_{i,j} = d_{j,i}$であるとき
	- 非対称 TSP
		- 任意の$i$において、$d_{i,j} \not= d_{j,i}$であるとき

### 1 機械スケジューリング問題

- Single Machine scheduling Problem(SMP)
- 巡回セールスマン問題よりは有名ではない
- 1 台の機械で複数の仕事をこなすとき、いつからどの仕事をやればいいのかを考える問題
- ふわっとしすぎなので、ちょっと具体的に
- 仕事$i$に対して与えられる値は 3 つ
	1.  $p_i$ : 処理時間。仕事$i$を処理するのに$p_i$かかる
	1.  $r_i$ : 準備時間。仕事$i$は$r_i$より前に始めることはできない
	1.  $d_i$ : 納期。仕事$i$は$d_i$よりも前に処理しきりたい(しきりたいだけ。遅延してもいい)。
- 準備期間は絶対だけど、納期は絶対じゃないのが重要
- 定式化すると以下のようになる

$$
\begin{aligned}
	入力 &: n個の仕事V={1,\cdots,n}と各仕事iに対する処理時間p_i, 準備時間r_i, 納期d_i\\
	出力 &: f_{SMP}(\sigma) を最小化する仕事の順序\sigma
\end{aligned}
$$

- 評価関数$f_{SMP}(\sigma)$はいくつかある
	- 最終完了時刻
		- 最後の仕事の完了時間
	- 最大遅れ
		- 納期から最大どのぐらい遅れたか
		- 負の値をとれる
	- 遅れ和
		- 納期から遅れた分の和
		- 納期を守った場合は 0 になる
		- 必ず非負値になる

### 最大充足化問題と充足可能性問題

#### 最大充足化問題

- Maximum Satisfiability(MAXSAT)
- 情報系じゃないとまず知らない問題
- これに関しては言葉で説明するより具体例を出した方が早い
- ので、定式化

$$
\begin{aligned}
	入力 &: n変数から成るm個の節C_1,\cdots,C_nと各節の重みw_1,\cdots,w_n\\
	出力 &: f_{MAXSAT}(v) = \sum_{i=1}^m w_iC_i(v) を最大にするv\in\{0,1\}^n
\end{aligned}
$$

- は？という感じなので、n=3,m=4 の例

$$
\begin{aligned}
	C_1 &= y_1 \vee y_3, \: & \: w_1 = 2\\
	C_2 &= \bar y_2 \vee \bar y_3, \: & \: w_2 = 3\\
	C_3 &= y_1 \vee y_2 \vee \bar y_3, \: & \: w_3=1\\
	C_4 &= \bar y_1, \: & \: w_4 = 2
\end{aligned}
$$

- のとき、$v=(0,0,1)$が最適解となる。このとき、$C_1(v) = C_2(v) = C_4 = 1, C_3(v)=0$ となり、$f_{MAXSAT}(v) = w_1+w_2+w_4 = 7$となって、$f_{MAXSAT}(v)$が最大になる。

- 計算量
	- 最悪計算量は$O(2^N)$
		- $v$を全列挙すればよい。$v$の要素数は N 個なので、$2^N$通り調べればよい

#### 充足可能性問題

- Satisfiability Problem(SAT)
- 最大充足可能性問題とは違って、全ての節を満たせるかどうかが問題
	- $\sum_{i=1}^m C_i(v)=m$となるかどうか
- 定式化すると次のようになる

$$
\begin{aligned}
	入力 &: n変数から成るm個の節C_1,\cdots,C_n\\
	出力 &: \sum_{i=1}^m C_i(v) = mを満たすv\in\{0,1\}^nが存在するかどうか
\end{aligned}
$$

- 計算量
	- 最悪計算量は$O(2^N)$
		- $v$を全列挙すればよい。$v$の要素数は N 個なので、$2^N$通り調べればよい
		- 最大充足化問題と同じ

### ナップザック問題

- Knapsack Problem(KNAPSACK)
- 巡回セールスマン問題の次に有名なやつ
- ナップザックに物を詰めていくときに、一番価値を高めるならどれを詰める？という問題
	- 大きくても価値の低いものはあるし、小さくても価値の高いものはある
		- わたあめよりダイアモンドの方が価値が高い
- 定式化

$$
\begin{aligned}
	入力1 &: n個の要素集合V=\{1,\cdots,n\}の各要素iに対するサイズa_iと価値c_i\\
	入力2 &: ナップザックのサイズb\\
	条件 &: \sum_{i\in V}a_iz_i \leq b\\
	出力 &: f_{KNAPSACK}(z) = \sum_{i\in V} c_iz_iを最大にするn次元非負整数ベクトルz
\end{aligned}
$$

- 種類

	- 0-1 ナップザック問題
		- 物が各 1 つしかない場合

- 計算量
	- 0-1 ナップザック問題の時は$O(2^N)$
		- 各モノを入れるか入れないかの 2 通りを N 個のモノに対して評価すればよい
	- 普通のナップザック問題の時は最悪がない。無限に最悪になれる

### 一般化割当問題

- Generalized Assignment Problem(GAP)
- 複数の仕事を複数のエージェントに割り振るとき、誰に何を割り当てるとコストが最小になる？という問題
- エージェントは利用可能資源量$b_i$を持つ
	- 仕事をこなすことができる許容量のようなもの
- 仕事$j$をエージェント$i$に割り当てた時、コスト$c_{i,j}$資源の要求量$a_{i,j}$がかかる
	- 言い換えると、エージェント$i$は仕事$j$を賃金$c_{i,j}$で請け負い、資源$a_{i,j}$を使って仕事をする
- 定式化するとこうなる

$$
\begin{aligned}
	入力1 &: n個の仕事集合V=\{1,\cdots,n\}\\
	入力2 &: m個のエージェントW=\{1,\cdots,m\}\\
	入力3 &: 各エージェントi\in Wの利用可能資源量b_i\\
	入力4 &: 仕事j\in Vをエージェントi\in Wに割り当てた時のコストc_{i,j}と資源の要求量a_{i,j}\\
	条件 &: \sum_{\pi(j)=i} a_{i,j} \leq b_i (\forall i \in W)\\
	出力 &:  f_{GAP}(\pi) = \sum_{j\in V}c_{\pi(j),j}を最小にする割当\pi
\end{aligned}
$$

- 計算量
	- 最悪計算量は$O(N^M)$
		- N 個の仕事を割り当てる先がそれぞれ M 人のエージェントがいるため

## アルゴリズムの計算量とその評価

- アルゴリズムは計算量が存在する
	- 計算量は領域量と時間量に分解される
		- 領域量 : 必要なメモリの量
		- 時間量 : 必要な計算時間
- 問題の入力個数を$N$としたときに計算量がどのように表されるかが重要
- 多項式時間アルゴリズム
	- 問題の規模$N$と定数$k$に対し、計算量が$O(N^k)$となるようなアルゴリズム
	- 計算量が$O(k^N),O(N^N)$になると、$N$の大きさで計算量が爆発する(めちゃめちゃ大きくなる)ので実用的ではない。

## 組み合わせ最適化問題と計算の複雑さ

### クラス P とクラス NP

- 決定問題
	- 個々の問題例に対し、ある性質が成立するかを判定し、Yes/No の回答を要求する問題
		- 例えば、充足可能性問題は決定問題の一つ

#### クラス P(Polynomial)

問題$\Pi$ において次の条件を満たす多項式時間アルゴリズム$A$が存在するとき、問題$\Pi$ はクラス P に属する。問題$\Pi$ の任意の問題例 I に対し

$$
\begin{aligned}
	&Iの答えがYes &\to & AはIに対してYesを出力\\
	&Iの答えがNo &\to& AはIに対してNoを出力
\end{aligned}
$$

- クラス P は多項式時間アルゴリズムが存在する決定問題の集合を指す

#### クラス NP(Nondeterministic Polynomial)

問題$\Pi$に対して次の条件が成立するとき、クラス NP に属するという。

1. 問題$\Pi$の任意の問題例$I$と任意の解$s$が与えられたとき、$s$が$I$の実行可能解であるかどうかを判定する多項式時間アルゴリズム$A$が存在する
1. $I$の答えは次のように定義される

$$
\begin{aligned}
	&Iの答えがYes &\to& Iに対し実行可能解sが存在する\\
	&Iの答えがNo &\to& どのような解sもIの実行可能解ではない
\end{aligned}
$$

- クラス NP の定義は、決定問題の答えが Yes であることの証拠である解$s$を与えることができれば、それを多項式時間で確認できるという性質を表している
- $I$に対する Yes/No の出力を多項式時間で求めることは要求していない
	- 与えられた解に対し、制約条件のチェックが多項式時間でできることは要求されている
	- 解$s$の生成は多項式時間でできる必要はない
		- 生成できるのなら列挙法でもよい

## メタ戦略と役割

- 組み合わせ最適化問題の多くはクラス NP に属する問題であり、つまりは解くのが非常に難しい。というか解けない
- 解けないからと言って諦めるわけにはいかない
- 人間、最適解ではなくても、最適解に近そうな精度の高い解が求まれば満足する
- というわけで、近似解法が用いられる
- 近似解法の基本戦略の例
	- 貪欲法
		- 構築法の一種
		- 局所的な評価値に基づいて実行可能解を直接構成する方法
	- 局所探索法
		- 改善法の一種
		- 与えられた解を簡単な操作で改善する手続きを反復することで良い解を導く方法
		- メタ戦略は多少時間がかかってもより良い解を求めるような解法の一般的枠組みを与えるもの
			- 例としては
				- 遺伝的アルゴリズム
				- アニーリング法
				- タブー探索法

## 厳密解法

- 組み合わせ最適化問題に対して、近似解ではなく、厳密な最適解を求めるアルゴリズム

### 分枝限定法

- 考え方
	- 問題をいくつかの小規模な問題に分割して、そのすべてを解くことで等価的に元の問題を解くというもの
	- 分割は、一部の変数の 0-1 割当を個別に考察することによって実現される
- 分枝操作
	- 1 つの変数を固定して、2 つの部分問題を生成する操作
	- 部分問題を作る理由は、子孫(その部分問題以下)を探索しないようにするため
		- 子孫を調べる必要がなくなる場合は以下の 2 つ(or)
			1.  その値が元の問題の最適解を与えないことが分かったとき
			1.  その部分問題が元の問題の最適解を与えないことが分かったとき
		- 調べる必要がなくなったときに分枝木の子孫の探索を省略することを`限定操作`という
- 動的計画法
	- Dynamic Programing
	- 複数の部分問題の計算結果を記録しながら解いていく方法
	- 本に書いてあったの、めちゃめちゃわかりずらかったので、[wikipedia](https://ja.wikipedia.org/wiki/%E5%8B%95%E7%9A%84%E8%A8%88%E7%94%BB%E6%B3%95)見ましょう

# 第二章 近似解法の基本戦略

## 貪欲法

- 一番わかりやすい構築法
- 局所的な評価値に基づいて実行可能解を直接構成する方法
- 基本的に一本道のアルゴリズム

### 巡回セールスマン問題における貪欲法

巡回セールスマン問題において貪欲法は 2 つのパターンがある

1. 最近近傍法
	 - 今いる都市から一番近い都市を選んで移動していく方法
		 - もちろん、すでに訪問している都市は除く
1. 多断片法
	 - 今いる場所かどうかは関係なく、都市間の距離が短い順に道をつなげていく方法
		 - 都市から道が 2 本つながれている場合は除く
	 - また、部分巡回路ができてはいけない
		 - 読んで字のごとく、全ての都市を回らないうちに巡回路が作成されてはいけない

## 局所探索法

- 近傍
	- 実行可能解$x\in F$に対し、$x$に少しの変形を加えることによって得られる解集合$N(x) \subset F$を$x$の近傍という
- 局所探索法(Local Search)
	- 適当な解$x \in F$ から始め、$x$の近傍$N(x)$に改善解$x'$があれば、$x := x'$として改善していく
	- $N(x)$内に改善買いがそれ以上存在しないような$x$を近傍 N の`局所最適解`という
	- 一つの問題に対し、局所最適解はいっぱいある。
	- 局所最適解に対し、実行可能解集合全体の最適解を`大局的最適解`という
	- 別名
		- 反復改善法
		- 山登り法
		- 近傍探索法
- 移動戦略
	- 近傍$N(x)$内の改善解は、一般に複数存在する
	- 近傍をどのような順序で調べ、どの解を次の解に採用するかは様々な戦略がある(=移動戦略)
	- 代表的なもの
		- 即時移動戦略
			- 近傍$N(x)$内をランダムな順序で調べて、最初に見つかった改善解に移動する
		- 最良移動戦略
			- $N(x)$内の解を全て調べて、最良解に移動する
- 近傍の作り方
	- 数学的には写像$N : F \to 2^F$であれば何でもよい
	- 性能の高い曲探索法を得るには、$N(x)$内に改善解が存在する傾向が高くなるように定めることが重要
	- 例) 巡回セールスマン問題や 1 機械スケジューリング問題のように解が要素集合$V={1,\cdots,n}$の順列$\sigma$で表される時
		- 挿入近傍 : $N_{ins} = {\sigmaの一つの要素をほかの位置に挿入することにより得られる解} $
		- 交換近傍 : $N_{swap} = {\sigmaの2つの要素の位置を交換することにより得られる解} $
	- 挿入近傍を拡張し、定数$\lambda > 0$に対し以下のようなものも考えられている

$$
\begin{aligned}
	N_{\lambda -ins}(\sigma) = {\sigma において連続する\lambda個以下の要素をほかの位置に挿入することで得られる解}
\end{aligned}
$$

- - Or-opt 近傍
		- 巡回セールスマン問題において$N_{\lambda -ins}(\sigma)$ において $\lambda = 3$としたもの
	- $\lambda-opt近傍$
		- $\lambda$本の枝を入れ替えることにより得られる巡回路の集合
		- 巡回路$\sigma$の枝集合を表す$E_{tour}(\sigma)$を用いると、定数$\lambda > 1$に対して

$$
\begin{aligned}
	N_{\lambda -opt} = {\sigma' | |E_{tour}(\sigma') / E_{tour}(\sigma) | \leq \lambda}
\end{aligned}
$$

- - 任意の$\lambda > 0$に対して、$N_{\lambda-ins}(\sigma) \subseteq N_{3-opt}(\sigma) $が成り立つ
	- $\lambda$反転近傍
		- 最大充足化問題のように解が n 次元 0-1 ベクトル$v={v_1,\cdots, v_n}$で表される場合は、定数$\lambda > 0$に対して

$$
\begin{aligned}
	N_{\lambda-flip}(v) = \{v' | vとv'のハミング距離は\lambda\}
\end{aligned}
$$

## 探索空間とペナルティ関数

- 探索空間
	- 探索の対象となる解集合
	- 実行可能解を生成することが簡単な場合は探索空間=実行可能領域としてよい
	- 実行可能解を生成することが容易でない場合は工夫が必要
- 評価関数$\tilde{f}$の定め方
	- ペナルティ関数法
		- 解が実行可能でないときの制約違反の程度をペナルティ関数として表し、目的関数に加えて評価関数とする方法
	- 例) 一般化割当問題
		- エージェントに仕事を割り振るやつ
		- 入力、条件、出力は以下の通り(復習)

$$
\begin{aligned}
	入力1 &: n個の仕事集合V=\{1,\cdots,n\}\\
	入力2 &: m個のエージェントW=\{1,\cdots,m\}\\
	入力3 &: 各エージェントi\in Wの利用可能資源量b_i\\
	入力4 &: 仕事j\in Vをエージェントi\in Wに割り当てた時のコストc_{i,j}と資源の要求量a_{i,j}\\
	条件 &: \sum_{\pi(j)=i} a_{i,j} \leq b_i (\forall i \in W)\\
	出力 &:  f_{GAP}(\pi) = \sum_{j\in V}c_{\pi(j),j}を最小にする割当\pi
\end{aligned}
$$

- - - 探索基準 GAP-1
			- 探索空間を任意の割当$\pi : V \to W$の集合都市、評価関数を以下にようにしたもの

$$
\begin{aligned}
	\tilde{f}(\pi) = \sum_{j\in V}c_{\pi(j),j} + \sum_{i\in W}\alpha_i \times max \{(\sum_{j\in V, \pi(j)=i} a_{i,j}) - b_i ,0 \}
\end{aligned}
$$

- - - - ただし、$\alpha_i > 0$はパラメータ
			- 評価関数の第 2 項は各エージェント$i$での資源制約(条件)の違反に対するペナルティ($\alpha_i$が大きければ大きいほどペナルティが重くなる)
- 実行不可能解を含む探索空間を採用した場合には、さらに評価関数や目的関数に工夫が加えられる
	- 探索をスムーズに行うため
- 探索空間$\tilde{F}の作り方$
	1.  $\tilde{F} = F$ : 実行可能領域をそのまま探索空間とする
	1.  $\tilde{F} \subseteq F$ : 制約条件の一部を緩和し、実行不可能解も含めて探索空間とする
	1.  解空間$F$とは異なる探索空間$\tilde{F}$を用意し、探索空間から実行可能領域への写像$\pi : \tilde{F}\to F$を用いて探索を行う - 実行可能領域への写像を設計することが困難な場合は実行不可能領域も含めた解空間への写像を考える
- $\tilde{F}と\tilde{f}$に関するまとめ
	- 問題の定式化が行われても、探索空間と解の評価法には様々な工夫が可能
	- 問題の性質に応じて探索空間と解の評価法をどう定めるかでアルゴリズムの性質が大きく異なる
	- 記号の統一
		- $F$ : 実行可能領域
		- $\tilde{F}$ : 探索空間
		- $f$ : 目的関数
		- $\tilde{f}$ : 評価関数(目的関数にペナルティを加えたもの)
	- 暫定解と暫定値
		- 暫定解 : 探索中に得られた最良の実行可能解
		- 暫定値 : 暫定解の目的関数値
- 局所探索法の一般的記述
	- 近傍の定義
		- 写像$N : \tilde{F} \to 2^{\tilde{F}}$
	- 局所探索法
		- 適当な探索解$x\in \tilde{F}$から始める
		- 次の操作を近傍内に改善解が存在しなくなるまで反復する方法
			- $x$の近傍$N(x)$内に$\tilde{f}(x') < \tilde{f}(x) $をみたす解$x'$があれば$x:=x'$と移動する操作
	- 近傍$N$と評価関数$\tilde{f}$に関する局所最適解は以下のように定義される
		- 全ての$x' \in N(x)$に対して、$\tilde{f}(x') \geq \tilde{f}(x) $を満たす解$x \in \tilde{F}$
	- 局所探索法の手続き(初期解$x$)
		1. $k:=1, x^{(1)}:=x$とする
		1. $\{x\in N(x^{(k)}) | \tilde{f}(x) < \tilde{f}(x^{(k)}) \} = \emptyset　ならば、x^{(k)}$を出力して終了。
		1. 改善解$x'\in \{x\in N(x^{(k)}) | \tilde{f}(x) <\tilde{f}(x^{(k)}) \}$を一つ選んで、$x^{(k+1)} := x'$としたのち、$k := k+1$としてステップ 2 へ

# メタ戦略の基礎

## メタ戦略の概要

- メタ戦略とは
	- 様々なアルゴリズムを含めた総称
	- 代表的なもの
		- ランダム多スタート局所探索法
		- 進化計算
			- 遺伝的アルゴリズム
		- アニーリング法
		- タブー探索法
	- 変形したもの
		- 遺伝的局所探索法
			- 遺伝的アルゴリズムに局所探索法を組み込んだもの
		- GRASP 法
			- 多スタート局所探索法の初期解生成ルーチンとして、欲張り法にランダム性を組み合わせたもの
		- 反復局所探索法/可変近傍探索法/アント法
			- 多スタート局所探索法の初期解生成に過去の探索で得られた解を利用するもの
		- 閾値受理法/大洪水法
			- アニーリング法を単純化したもの
		- 誘導局所探索法
			- タブー探索法を単純化したもの
	- 基本的な構造
		1. 過去の探索の履歴を利用して新たな解を生成する
		1. 生成した解を評価し次の回の探索に必要な情報を取り出す
		- つまりは、以下のアイデアの集合がメタ戦略
			- 生成された解のどのような情報を探索履歴として記憶するか
			- 探索の履歴をどのように利用して新たな解を生成するか、
- Proximate Optimality Principle(POP)
	- 「良い解どうしは似通った構造を持っている」という概念
	- POP が成立していれば、良い解に似通った買いの中により良い解が見つかる可能性が高いと考えられる
- 探索の集中力
	- 局所探索法の改善力と POP に基づいてよい解の近くを集中的に探索しようとする考え方
- 探索の多様化
	- 時々、これまで生成してきたかいとは構造の異なる会を生成する考え方
	- 似通った構造の解を探索することに力を入れすぎると、同じ階を何度も探索してしまって、無駄が多くなる恐れがあるため

## メタ戦略の一般的枠組み

- メタ戦略の枠組み
	1.  初期解生成 : 初期解$x$を生成する
	1.  局所探索 : $x$を一般化された局所探索法により改善する
	1.  反復 : メタ戦略の終了条件が満たされれば暫定解を出力して探索を終了する。そうでなければ 1 へ戻る
- 局所探索法の定義
	- 与えられた初期解$x\in \tilde{F}$から始める
	- 近傍$N(x) \subset \tilde{F}$内の解に一定のルールで移動する操作を、局所探索の終了条件が満たされるまで反復する
- 局所探索法の動作を定める時は局所探索時に以下を決める必要がある
	- 近傍$N(x)$の定義
	- 解の評価関数$\tilde{f}$
	- 移動戦略
	- 終了条件
- メタ戦略とは以下のいずれかに対する工夫であると捉えることが可能である
	- 初期解生成
	- 局所探索 : 近傍$N(x)$の定義
	- 局所探索 : 解の評価関数$\tilde{f}$
	- 局所探索 : 移動戦略
	- 局所探索 : 終了条件
	- 反復
- 様々なアイデアを具体的に実現するために
	- 各ステップを独立に設計するのではダメ
	- 他のステップの特徴を考慮しながら、総合的に設計することが必要

## 初期解の生成 : 多スタート法

- 多スタート法
	- 初期解生成法
	- 反復するごとに、以前の探索の履歴とは特に関係ない解を生成する方法
- 初期解の生成法として、もっとも簡単な方法
	- 反復ごとにランダムな解を利用すること
	- 利点 : ランダムな解を生成することは容易なので、多数の異なる会を高速に生成できる
- 初期解をランダム解ではなく質の良い解を求めると、性能の向上が期待できる
	- 例えば初期解の方法に貪欲法を用いる
	- 貪欲法だと、異なる初期解を多数生成する目的には適してない場合がある
		- 常に同じ階が出力されるため
	- 克服するため、ランダム化貪欲法を利用する方法が考えられる
	- 全くランダムな解に比べると初期解の平均的な精度が向上することが期待できる

## 初期解の生成 : 適応的多スタート法

- 多スタート法では限界がある
	- 各反復が独立な思考のため
	- 後に来る反復の方が良い解になる確率は高くない
		- 最初の反復と、2 回目の反復は互いに独立なので
	- そのため、反復回数を増やす効果は急速に小さくなる
- 適応的多スタート法
	- 初期解生成法
	- 初期解を生成するときに、これまでの探索の履歴を積極的に利用する手法
	- もっとも簡単なものは、過去の探索で得られた良い解にランダムな変形を加えたものを初期解とするもの
		- 過去に得られた良い解の周辺をより丹念に探索することができる
		- とともに、ランダムな変形によってこれまでの探索とは多少異なる領域を調べることができる
	- 初期解生成法のもう少し複雑な方法
		- 過去の探索で得られた 2 つ以上の解を組み合わせること
		- 近傍操作とは別に、解を組み合わせるための新たなオペレータを設計する必要がある
			- 多点交差法とか
- 方法
	- 上にあげたものはこれまでに得られた良い解のいくつかを保持しておき、それらを変形することによって次の初期解を生成する方法
	- 保持しておく情報として、解の部分構造や統計量を用いる方法も考えられる
		- 例えば、、、
			1.  多くのよい解に共通して含まれる解の構成要素に対して、その構成要素を含む解の質と構成要素の出現頻度に応じた得点をつけておく。
			1.  得点が高い構成要素ほど選ばれやすくなるように傾斜をかけてランダムに初期解を生成する方法 - 他にも、得点に基づいた欲張り法によって初期解を生成する方法
	- 解の構成要素よりもやや大きな単位で解の部分的な構造を記憶して起き、それらを組み合わせることによって初期解を生成する方法
		- 例えば巡回セールスマン問題において部分的な解構造としてはパスなどが考えられる

## 近傍

- 近傍は問題タイプに応じて様々な定義が可能
	- POP が成立するか
	- POP が成立しないか
- メタ戦略が大きな力を発揮するとき
	- POP が成立する場合に大きな効果を発揮できる
	- 複数個の近傍を用意し、探索の状況に応じて度の近傍を使うかを適応的に変化させる方法
- 近傍の設計の際のサイズ
	- 一般に、近傍を大きくすれば、得られる局所最適解の制度は上がる
	- 例) 1 次元の探索空間に対して、以下のように近傍を定義する
		- $N_1 = \{x' | |x'-x| \leq 1\} $
		- $N_2 = \{x' | |x'-x| \leq 2\} $
		- この時、$N_1$に関する局所最適解の多くが$N_2$では局所最適解ではなくなる
	- 大きな近傍の利用は、小さな近傍に関する局所最適解からの脱出を図る手法の一つと捉えることもできる
- 近傍の探索オーダー
	- 近傍$N(x)$の中に改善買いが存在するかどうかの判定は$O(|N(x)|)$かかる
	- 近傍を大きくとると計算効率は落ちる
	- 近傍の大きさと計算効率はトレードオフ
	- 例)
		- 巡回セールスマン問題に対する$\lambda-opt近傍$
		- 近傍のサイズは町の数 n に対して指数的に増大する
			- $|N_{\lambda-opt}(\sigma)| = O(n^{\lambda}$のため
- 近傍探索を協力にする汎用的な手法
	- 小さな近傍操作を連鎖的に複数回反復することによって得る解集合を、改めて近傍と定義するもの
	- このルールによる近傍は、サイズが大きくなり、精度の向上が期待できる
		- 複雑な近傍操作によって到達できるような解の集合となるため
	- このルールを単純に実行すると、生成されえる会の数が指数的に増大して死ぬ
	- 問題構造を利用して、連鎖的な近傍操作の限定や反復の打ち切りをする
	- つまり、仮想的に大きな近傍を用意するものの、実際にはその中の有望な買いの身を探索しようとするアイデア

## 解の評価

- もっとも基本的なもの
	- 目的関数$f$をそのまま評価関数$\tilde{f}$として用いる方法
	- この方法だと、探索空間に実行不可能買いが含まれる場合死ぬ
		- 実行不可能買いにはペナルティを与えるなどの工夫が必要
	- 同じ目的関数値を持つ解が多数存在し、解構造に大きな変化を加えなければ、目的関数地が変化しない場合も死ぬ
	- 問題に応じて探索に適した評価関数を用意しましょう
- より汎用的な手法
	- 評価関数$\tilde{f}$を適応的に変形することによって局所最適解からの脱出や、探索の多様化を実現する方法
	- 例えば、局所最適解に到達した時点で、評価関数$\tilde{f}$に何らかの摂動を加えるというもの
		- 十分な摂動を加えると、新しい評価では現在の解が局所最適解ではなくなる
		- そうすると、局所探索が継続できるので、局所最適解からの脱出が可能になる
		- ちなみに、摂動の加え方としてもっとの簡単なのは、ランダムな摂動を加えるもの
	- 前回の探索で得られた局所最適解の構成要素にペナルティを加えるもの
		- 現在の局所最適解が悪いものになるので、局所最適解からの脱出が図れる
		- 過去に探索した買いを再び探索する可能性が低くなることで、多様化も図れる
- 探索空間に実行不可能解が含まれる場合のペナルティ関数法
	- 通常、制約違反に対するペナルティと元の目的関数$f$の重み付き和で与えられる
	- $\tilde{f} = f(x) + \alpha \times (解xの制約違反のペナルティ)$
		- $\alpha$はペナルティ項の重み
	- 探索空間$\tilde{F}$において、評価関数$\tilde{f}$に関する最良の解が実行可能解であることを保障たいなら、$\alpha$を大きくすればいい
	- ただ、制約が厳しい問題では、実行可能解から実行可能解に移るときに実行不可能解を経由しなければいけない時が多い
		- そういうときは、ペナルティが大きいと移動ができなくなって探索ができなくなる
	- また、実行可能領域と実行不可能領域の境界付近に良い解が存在する場合が多い
	- というわけで、ペナルティを軽くして実行不可能領域も頻繁に訪れるようにすることで探索の効率化を図ることができる場合がある
		- ペナルティを軽くしすぎると、実行不可能解から抜けられなくなるので注意
	- 制約が複数あるなら、制約ごとに異なるペナルティを与えることも有効
		- 長期的に満たされていない制約のペナルティを徐々に大きくするなど
	- 局所最適解からの脱出の効果も期待できる
		- ペナルティ重みの適応的な制御は評価関数の摂動ともとらえられる

## 移動戦略

- もっとも基本的なもの
	- 常に改善解に移動するというもの
		- 即時移動戦略と最良移動戦略が代表的
	- これは局所最適解に到達すると探索が止まってしまう
	- 改善解以外への移動も許すことによって、局所最適解にたどり着いてもさらに探索を継続させたい
- 改悪解への移動
	- 改悪解への移動により、探索が局所最適解から脱出できたりできなかったりする
	- サイクリング
		- 改悪解に移動した結果、いくつか探索を行い、元のところに戻ってくること
		- 当然起こってほしいわけがない
	- 単純な方法
		- 近傍内に改善解があればどれかに移動し、改善買いがないときは、近傍内からランダムに一つを選んでそちらに移動する方法
		- 評価値のよいものほど選ばれる確率に傾斜をかける工夫
			- 改善解以外への移動を行う場合でも、評価値のよい解に移動する方が望ましいため
		- 改悪の程度が小さいもののみを候補とする工夫
		- サイクリングが起きやすいので、近傍内に改善買いが存在するときでも改悪解への移動を許すことでランダム性を高め、直前の解に戻りにくくする方法が良くとられる
	- サイクリングの原因となる探索済みの解を記憶しておき、その解への移動を禁止する方法
		- ランダム性を利用してサイクリングを防ぐのではない方法
		- ランダム性を用いないので、ルールをうまく作ると綿密な探索ができる

## 終了基準

- 良く用いられるルールは次のようなもの
	- 最良ぽい解にたどり着いた時に終了する
	- あらかじめ決めておいた移動回数(反復回数)や計算時間が来た時に終了する
	- あらかじめ決めておいた反復回数の間に暫定値が改善されなかったときに終了する

# メタ戦略の実現

- メタ戦略の枠組み
	1.  初期解生成 : 初期解$x$を生成する
	1.  局所探索 : $x$を一般化された局所探索法により改善する
	1.  反復 : メタ戦略の終了条件が満たされれば暫定解を出力して探索を終了する。そうでなければ 1 へ戻る

## 多スタート局所探索法

- 初期解生成に多スタート法を用い、局所探索法には単純局所探索法を用いた、もっとも単純な方法の総称
- メタ戦略の中では古くから広く用いられてきた
- 枠組み
	1.  ランダムか貪欲法を用いて初期解$x$を生成する
	1.  解$x$を単純局所探索法により改善する
- 以上の 2 ステップの反復し、最良の実行可能解を出力する方法
- 初期解を生成する場合は`ランダム多スタート局所探索法`と呼ぶ

## GRASP 法

- 多スタート局所探索法の一種
- 初期解生成にランダム化貪欲法を利用するのが特徴
- 枠組み
	1.  ランダム化欲張り法により初期解$x$を生成する
	1.  解$x$を単純局所探索法により改善する
- GRASP 法は単純であるが、様々な組み合わせ最適化問題に適用され、一定の成果を収めている

## 反復局所探索法

- 過去の探索で得られた良い解にランダムな変形を加えたものを初期解として、単純局所探索法を反復する方法
- どのようなものか
	1.  初期解生成に工夫を加えた適応的多スタート法だと捉えることができる
	1.  移動戦略に工夫を加え、探索が局所最適解に到達したときにいかにような特別ルールを採用した方法と捉えることができる 1. メモリに蓄えられたほかの解に移動する 1. 近傍内のランダムな買いに移動する
- 可変近傍探索法
	- 初期解生成を上記の 2. の方法を用いる時、使用する近傍のサイズを抵抗的に変化させる方法
	- 近傍サイズを初めは小さく設定する
	- 初期解の生成に用いる局所最適解と局所探索法によって新たに得られた解を比較し
		- 改善が見られない場合は近傍サイズを大きくする
		- 改善解が得られた場合は近傍サイズを元に戻す
- 枠組み

	1.  適当な解を初期解として単純局所探索を行い、局所探索会$x$を得る。$x_{seed} :=x, l := 1 $とする
	1.  $N^{l}(x_{seed})$よりランダムに一つ解を選び、$x'$とする
	1.  $x'$を初期解として単純局所探索を行い、局所最適解$x$を得る
	1.  $\tilde{f}(x) \leq \tilde{f}(x_{seed})ならば確率1で、\tilde{f}(x) > \tilde{f}(x_{seed})ならば、確率e^{-\tilde{f}(x)-\tilde{f}(x_{seed})/t} で以下の手続き1を行う。手続き1を行わない場合手続き2を使う$ 1. x\_{seed} := x, l := 1 1. l := min(l+1, l\_{max})
	1.  終了条件を満たせば、暫定解を出力して探索終了。そうでなければステップ 2 に戻る

- 上記の枠組みは反復局所探索法だけでなく、一般的な CLO 法と VNS 法も含んでいる
	- パラメータ$l_{max}$と$t$を
		- Johnson の単純反復局所探索法 : $l_{max}=1, t=0$
		- CLO 法 : $t > 0$
		- VNS 法 : $l_{max} \geq 2$
- 上記の枠組みで$t=0, l_{max}=1$とした場合、常に最新の暫定解を$x_{seed}$として、それに小さな変形を加えた解を次の初期解に用いるので集中化の能力が高い

	- 通常、良い解は１か所に集中しているのではなく、探索空間に散らばっているので、解の探索の多様化をしないといけない
	- 実際、$t=0, l_{max}=1$とした場合、探索の初期では高い性能を示すが、計算時間が長くなってくると改善能力が急速に低下する

- パラメータ$t$は通常定数
	- アニーリングの方に動的に制御する方法もある
	- $t$を大きくすると多様化の効果が高まるが、集中化の効果が低下する
	- $t$の調整は面倒なので、$t=0$とするのが安全
		- $t=\infty$とすると性能が落ちる場合が多い
	- 方法
		- 多様化が必要と思われるときにのみ t を大きくする
			- ある程度の期間暫定解が更新されない時など
		- 暫定解が更新されないは反復が連続するときは$t$を大きくしていき、暫定解が更新されたら 0 に戻すなどの方法も考えられる
- $l_{max} = 1$とする場合、ランダムな変形に用いる近傍$N^{(1)}$には、局所探索法に用いる近傍$N$と同じものを用いてよい
	- その場合、局所探索の結果すぐに$x_{seed}$に戻ってしまう可能性がある
		- ステップ 3 の直前において$x_{seed} \in N(x')$が成り立つ場合が多いので
	- これを避けるため、$N^{(1)}$には$N$と異なる近傍を用意する場合が多い
	- 例えば、巡回セールスマン問題で、局所探索法の近傍に 2-opt 近傍$N_{2-opt}$を用いた時
		- doublebridge 近傍をランダムな変形に利用するのが効果的と言われている
	- double bridge 近傍は$x_{seed}$に逆戻りする現象を防ぐ効果がある
		- 4-opt 近傍の特別な場合であるが、2-opt 近傍の操作を 2 解繰り返しても到達できないような解の集合になっている
- $l_{max} \geq 2$とする場合、$N^{(1)}$を小さな近傍とし、徐々に大きくしていくという方法がとられる
	1.  初めに小さな近傍を用いることで、$x_{seed}$の付近を集中的に探索しておく
	1.  しばらく改善解が見つからないときは大きな近傍を用いて$x_{seed}$から離れた解を生成し、多様化を図る
	- 例えば、巡回セールスマン問題で局所探索法の近傍に 2-opt 近傍$N_{2-opt}$を用いた場合
		- $N^{(1)}(x) = N_{(l+2)-opt}(x) \\ N_{(l+1)-opt}(x)$とする
			- つまり、ちょうど$l+2$本の枝を交換する操作を用いる
		- $N^{(l)}(x)$のサイズを大きくする速度をもっと遅くしたければ、
			- - $N^{(1)}(x) = N_{(\lceil\alpha l+2 \rceil)-opt}(x) \\ N_{(\lceil\alpha l+1\rceil)-opt}(x)$とする
	- ステップ 4 における$l$の更新ルールを適宜変更して、$N^{(l)}(x)$のサイズを変更する速度を、探索の状況に応じて適応的に変化させることも考えられる
- ステップ 4 はこれまでの探索で得られた良いかのうち一つを選ぶのであれば他のルールでもよい
	- 例えば、ある程度の期間暫定解が更新されず、多様化が必要とされる場合に以下のようなルールを用いる
		- ランダムな解を$x_{seed}$とする
		- ステップ 2 と 3 を反復していくつかの局所最適解を生成した後、評価値の高いものからいくつか選び、その中で現在の$x_{seed}$との距離が最大となるものを新たな$x_{seed}$とする
			- これは、解の質はできるだけよいのが良い + 多様化の為に次の$x_{seed}$は現在の$x_{seed}$からできるだけ遠いものが良いという考え方

## 遺伝的アルゴリズム

- 進化計算の一つ
- 生物の進化メカニズムを応用したもの
	- 生物の染色体の形成や突然変異によって新しい世代を形成し、弱いものが淘汰され強いものが生き残る性質
	- 操作
		- 交叉 : 選択した n 個体を交叉させて新しい世代を生み出す操作
		- 突然変異 : 確率で染色体を変異させる操作
		- 選択(淘汰) : 新しい世代と現代の世代から一定数だけを選び、次の世代とする操作
- 本書では局所探索法の初期解生成のメカニズムとして捉える
- 遺伝的局所探索法
	- 局所探索法として用いる時の呼称
- 枠組み

	1.  初期設定 : 初期開集合$P$を生成する
	1.  進化 : 以下のステップを反復し新たな解集合$Q$を生成する(今までの解集合は破棄)d 1. 交叉 : $P$の中から 2 つ以上の解を選び、それらを組み合わせることで新たな解を作る 1. 突然変異 : $P$から選んだ解、もしくは交叉で生成された解にランダムな変形を加える 1. 改善 : 交叉、突然変異で得られた新しい解を初期解とし、単純局所探索によって局所最適解を得て、解を$Q$に加える
	1.  選択(淘汰) : 新しく生成された解と元からあった解を併せた$P \cup Q$から$|P|$個の解を残し、それを新たな$P$とする
	1.  終了条件 : 終了条件が満たされれば暫定解を出力して探索を終了する。そうでなければステップ 2 に戻る

- 初期解設定、交叉、突然変異、改善、選択など各定め方はさまざまなバリエーションがある
	- 反復局所探索法と遺伝的アルゴリズムの違い
		- 反復局所探索法 : 保持している解は基本一つ
		- 遺伝的アルゴリズム : 複数個の解を保持して、それらを組み合わせることで新たな解を生成する

## アント法

- アントは蟻
- アリの巣から餌までの蟻行列のルートがフェロモンの情報によって定まるメカニズムからきてる
- 簡単な説明
	- 巣から餌までの最短距離に障害物があったため、ルート A とルート B の二つが作られた
	- 距離 ルート B < ルート A
	- 2 つのルートの分岐点では、どちらのルートが短いかわからないので、初期の段階では蟻はランダムにルートを選ぶ
	- 各蟻は通ったルートにフェロモンをばらまく
	- フェロモンは時間で揮発していく
	- フェロモンは蟻が多ければ多いほど増える
	- となると、距離が短いルート B の方がルート A よりフェロモンが揮発しないので、より濃く残る
	- より濃くフェロモンの残っているルート B の方を蟻は選びやすくなるので、最終的には全ての蟻が距離の短いルート B を選ぶようになる
- 探索法への使い方
	- 探索中に得られた解の構成要素に得点(つまりはフェロモン)を追加していく
	- フェロモンの情報によって修正された局所的評価を用いて、ランダム化欲張り法に従って、良い解に共通する構成要素を置く含むような初期解を生成する
- 枠組み
	1.  解の構成要素全てに対し、フェロモンの値を初期化する
	1.  以下のステップを反復して、新たな解集合$Q$を得る(今までの解集合は破棄) 1. フェロモンの値により修正された局所的評価に基づいたランダム化欲張り法を用いて解を生成する 1. 得られた解を初期解とし、単純局所探索法を適用して局所最適解を得て、得られた解を$Q$に加える
	1.  $Q$の解に含まれる構成要素に対し、フェロモンの情報を更新する
	1.  終了条件が満たされれば解を出力して終了。そうでなければステップ 2 へ戻る
- 様々な方法がとれるステップがある
	- ステップ 2-1 : フェロモンの情報をどのように利用して欲張り法の局所的評価を行う
	- ステップ 3 : どのようにフェロモンの情報を更新するか

## Boese らの適応的多スタート法

- メタ戦略のステップ 1 の初期解生成に、解の構成要素に対する統計量を利用する単純な方法
	1.  過去の探索で得られた良い解に共通して含まれている構成要素に得点を与える
	1.  構成要素がより多く含まれるように、得点に基づいて解をランダムに生成するもの
	- 基本的な考え方はアント法と似ている
- 以下では巡回セールスマン問題に対する構成例を紹介する。
	- 現在保持している解集合$P$に対し次のように定義する

$$
\begin{aligned}
	r_{ij} &= \sum_{\{i,j\}\in E_{tour}(\sigma), \sigma \in P} \frac{1}{f_{TSP}(\sigma)}\\
	q_{ij} &= exp(\frac{r_{ij}}{\sum_{\sigma \in P} (1 / f_{TSP}(\sigma))}-1)
\end{aligned}
$$

- - $E_{tour}(\sigma)は巡回路\sigmaに含まれる枝集合$
	- $E_{TSP}(\sigma)$は巡回路の長さ
	- 枝$\{i,j\}がPの中のよい解に多く含まれていればいるほどr_{ij}とq_{ij}の値が大きくなる$
	- これらを用いて多断片法と類似の方法にランダム性を加えた方法で初期解を生成する
		- 多断片法では、枝を距離$d_{ij}$の短い順に追加していった
		- ここでは$d_{ij}の代わりにr_{ij}$を用いて、大きい値を優先する点が異なる
- 枠組み
	1.  $E_{sol} := \emptyset, E_{cand} := \{\{i,j\} | r_{ij} > 0\}$
	1.  $E_{end}に含まれる正当な枝の中で、r_{ij}が最大となる枝を選び、それを\{i,j\}とする。E_{cand} := E_{cand} \\ \{\{i,j\}\}とする。$
	1.  $0 \leq r \leq 1となるrをランダムに選び、 r < q_{ij}ならば E_{sol} := E_{sol} \cup \{\{i,j\}\}とする$
	1.  $E_{cand}$に正当な枝が存在すれば、ステップ２に戻る
	1.  $|E_{sol}| = nならばE_{sol}$を出力して終了。
	1.  $E \\ E_{sol}の中から正当な枝をランダムに一つ選び、E_{sol}に追加する。ステップ5に戻る$
	- $nは街の数、Eは全枝の集合、E_{sol}は構築中の巡回路に含まれる枝集合、E_{cand}はr_{ij}が正の値をとる枝の中で未走査のもの$
	- 以下の条件を満たすとき(and)、枝$\{i,j\}$のことを正当な枝と呼ぶ
		- $E_{sol}に枝\{i,j\}$を追加しても、各頂点に接続される枝の数が 2 以下である
		- $E_{sol}に枝\{i,j\}$を追加しても、部分巡回路が生成されない

## 誘導局所探索法

- メタ戦略のステップ 2-2 の評価関数$\tilde{f}$の構成に工夫を加えた方法
	- $\tilde{f}$を適応的に変形することによって局所最適解からの脱出を実現するもの
	- 前回の探索で得られた局所最適化$x$の構成要素の中でコストの大きいものにペナルティを付加する
- 十分なペナルティを与えると、新しい評価の下では$x$は局所最適解ではなくなるため、探索が続行する
	- $x$の近傍を$x$を排除しつつ新しい視点で探索することができる
- 枠組み
	1.  全ての構成要素のペナルティを 0 とする。初期解$x$を生成する
	1.  ペナルティによって修正された評価関数$\tilde{f}$を用いた単純局所探索法を適用して、$\tilde{f}$の元手の局所最適解$x'$を得る
	1.  $x'$に基づいてペナルティの値を修正する
	1.  終了条件が満たされれば暫定解を出力して探索終了。そうでなければ、$x:=x'$としてステップ 2 へ
- 実現するために必要な工夫
	- 解の構成要素をどうするか
	- ステップ 2 において評価関数をペナルティによってどのように変形するか
	- ステップ 3 においてペナルティをどう更新するか

## 評価関数摂動法

- 通常の評価関数とランダムな摂動を加えた評価関数を交互に利用して局所探索を行う方法
- これも局所最適解からの脱出を図るもの
	- 単純局所探索法において局所最適解に到達したとき
		- 評価関数にランダムな摂動を加えたものを新たな評価関数として用いて局所探索を行う
	- 新しい評価関数において局所最適解に到達したとき
		- 元の評価関数を用いて局所探索を行う
- 枠組み
	1.  初期解を生成し、$\tilde{f}$を評価関数とした単純局所探索で局所最適解$x$を得る。$x_{seed}:=x$とする
	1.  評価関数$\tilde{f}$にランダムな摂動を加え、$\tilde{f}_{rand}$を生成する
	1.  $x_{seed}$を初期解とし、$\tilde{f}_{rand}$を評価関数として単純局所探索法を行い、局所最適解$x'$を得る
	1.  $x'$を初期解とし、$\tilde{f}$を評価関数として単純局所探索を行い、局所最適解$x$を得る
	1.  $\tilde{f}(x)\leq \tilde{f}(x_{seed})$ならば$x_{seed} := x$とする
	1.  終了条件を満たせば暫定解を出力して探索終了。そうでなければステップ 2 へ
- 評価関数に摂動を加える方法はいろいろ考えられる
	- 例えば巡回セールスマン問題で考える
		- 各街$i$に対して座標をランダムな方向に$\epsilon_i$ずらすことで、ランダムな摂動を与えることができる

## 探索空間平滑化法

- 単純局所探索法における局所最適解の移動がより滑らかになることを目的としている
- 評価関数に定められた(ランダム性を含まない)摂動を加える方法
- パラメータ$\alpha \geq 1$を含む評価関数$\tilde{f}^\alpha$を以下の境界条件を満たすように定義する

$$
\begin{aligned}
	\tilde{f}^{(1)}(x) &= \tilde{f}(x) & (\forall x \in \tilde{F})\\
	\tilde{f}^{(\infty)}(x) &= c &　(\forall x \in \tilde{F})(cは定数)
\end{aligned}
$$

- $\alpha = 1$では$\tilde{f}^{(\alpha)}$はもとの評価関数と等しい
- $\alpha = \infty$では$\tilde{f}^{(\alpha)}$は常に$c$を返す。非常に平滑化された関数となる
- $\alpha$の値を変化させつつ局所探索を行う
- $\alpha$の値は、通常、アルゴリズムの進行とともに徐々に小さくしていき、最後は 1 になるように制御する
- 枠組み
	1.  適当な初期解$x$を生成する。$\alpha$を初期化する
	1.  $x$を初期解都市、$\tilde{f}^{(\alpha)}$を評価関数として単純局所探索を行い、局所最適解$x'$を得る
	1.  終了条件を満たせば暫定解を出力して探索終了。そうでなければ$x:=x'$とし、$\alpha$の値を更新して、ステップ 2 に戻る
- 意味が分からないので巡回セールスマン問題で具体例
	- 街$i$と街$j$間の距離を$d_{ij}(0 \leq d_{ij} \leq 1)$とする
	- $\bar{d}$を平均距離とする

$$
\begin{aligned}
	d^{(\alpha)}_{ij} =
		\begin{cases}
			\bar{d} + | d_{ij} - \bar{d} | ^\alpha ,& d_{ij} \geq \bar{d}\\
			\bar{d} - | d_{ij} - \bar{d} | ^\alpha ,& d_{ij} < \bar{d}\\
		\end{cases}
\end{aligned}
$$

- このとき$\alpha$が十分に大きいと全ての$i$と$j$に対し$d_{ij}^{(\alpha)}$はほとんど等しい
- 単純局所探索が局所最適解で止まるたびに$\alpha$を徐々に小さくしていくと、$d_{ij}^{(\alpha)}$は$d_{ij}$に近づく
- この変形距離を用いることで、探索の初めにコストに大きな影響を与える会の構造を大雑把に把握し、徐々に細かい構造を修正していくことができる

## アニーリング法/焼きなまし法

- Simulated Annealing
- 現在の解$x$の近傍$N(x)$内の各解$x'$に、解の良さに応じた遷移確率を設定し、それによって次の解を選ぶ
- 改悪解でも遷移する確率を与えることにより、局所最適解からの脱出を図るもの
- 遷移確率は、物理現象の`焼きなまし`のアイデアから`温度`のパラメータ$t$を設定し調整される
- 枠組み
	1.  初期解$x$を生成する。初期温度$t$を定める
	1.  以下のステップをループの終了条件が満たされるまで反復 1. 近傍$N(x)$内の解をランダムに一つ選び$x'$とする 1. $\Delta := \tilde{f}(x') - \tilde{f}(x)$とする - $x'$が改悪解ならば$\Delta > 0$ 1. $\Delta \leq 0$ならば確率 1。そうでなければ確率$e^{-\Delta/t}$で$x := x'$(解$x'$を受理)
	1.  反復の終了条件が満たされれば暫定解を出力して探索終了。そうでなければ温度$t$を更新してステップ 2 へ
- 温度$t$
	- 初期段階では高く設定する
		- つまりは、改善解だろうが改悪解だろうがランダムに遷移する
	- 探索が進むにつれて温度を下げていく
		- 探索が進むと改善解に移動する確率が上がっていく
- このアルゴリズムを実現するのに必要なもの
	- 初期温度の定め方
	- ループの終了条件
	- 温度の更新方法
	- 探索の終了条件
- 初期温度の決め方
	- 問題ごとに適切な値が大きく異なるため、定数に固定するのは良くない
	- 通常、探索の初期段階で生成した解の中で受理されるものが$p_{init}$となるような初期温度$t$を定める
		- $p_{init}(0 < p_{init} < 1)$ :与えるパラメータ
	- $p_{init}$から温度$t$を求める方法
		- $t$を適当に与えた上で実際にアニーリング法の初期段階を実行するのを何回か反復すればよい
- ループの終了条件
	- 最も簡単なものはループを$\alpha_{loop} * |N(x)|$回反復したら終了
		- $\alpha_{loop}(>0)$ : 与えるパラメータ
	- 工夫したものに次のようなものがある
		- 温度が高い時は解が受理される確率が高い
			- つまりは、探索はランダムウォークに近い挙動をとる
		- そのため、温度が高い状態で探索を長く行っても無駄が多い
		- そこで、ループの中で受理された解が$\alpha_{cut} * |N(x)|$回になったらループを抜ける、というルールを加える
			- $\alpha_{cut}(>0)$ : $\alpha_{loop}$より小さい値
- 温度の更新方法
	- 冷却スケジュール : 温度の更新方法
	- 幾何冷却法 : 最も簡単で実用的なもの
		- $\Beta_{temp}$を用意し、$t := \Beta_{temp} * t$で更新する方法
	- 少し適応的な要素を加えた方法
		- アニーリング法の効果が最も現れるのは温度が中途半端な時
			- 温度が高い時 : 探索の挙動はランダムウォーク
			- 温度が低い時 : 探索の挙動は単純局所探索
		- そこで、暫定解が見つかった時の温度$t_{found}$を記憶しておき、暫定解が暫く見つからなかった時に温度を$t := t_{found}$といったん高くする方法
	- アニーリング法は最適解への漸近収束性がある
		- 収束性を保障するためには、温度を下げる速度を十分に遅くしなければいけない
		- 対数冷却法 : 十分に温度低下の遅い冷却法
			- 解を一つサンプルするたびに温度を下げる
				- つまりはステップ 2 のループを 1 回で終了する
			- 第$k$反復での温度を$c$を十分大きな定数として$c/(log(k+1))$と定める方法
			- 温度がなかなか下がらず、実用性がないことが知られている
	- ステップ 2 の終了条件とステップ 3 の温度更新方法は密接に関係している
		- ループの反復回数と温度の下げる速度はトレードオフの関係にある
		- 例えば
			- 幾何冷却法において$\Beta_{temp}$を 0.95 などに固定しておき、$\alpha_{loop}$のみ調整する方法
				- パラメータ調整の手間を省きながら、ある程度の性能が期待できる
			- $\alpha_{loop}$を 1 回に固定しておき、温度の更新ルールで調整する方法
				- 解をサンプルする回数は$|N(x)|$に比例する程度には必要なので、$\Beta_{temp}$のみで調整を行おうとすると、問題のサイズが変わるたびに調整しなおす必要がある。辛い
- 探索の終了条件
	- 温度が十分低くなったと思ったら探索を終了する
	- 例えば
		- ステップ 2 のループ中で生成された解が受理される頻度が$p$以下となるような反復が$r$回続いたら終了するというルール

## 閾値受理法と大洪水報

- 閾値受理法 : Threshold Accepting
- 大洪水報 : Great Deluge Algorithm

### 閾値受理法

- 枠組み
	1.  初期解$x$を生成。初期閾値$r$を定める
	1.  次のステップをループの終了条件が満たされるまで反復する 1. $N(x)$内の解をランダムに 1 つ選び$x'$とする 1. $\Delta := \tilde{f}(x') - \tilde{f}(x)$とする($x'$が改悪解ならば$\Delta>0$) 1. $\Delta < r$ならば$x:=x'$とする(解$x'$を受理)
	1.  反復の終了条件が満たされれば暫定解を出力して探索終了。そうでなければ閾値$r$を更新した後ステップ 2 に戻る
- 閾値$r$は探索の初期の段階では大きく設定して起き、探索が進むにつれ小さくしていく
	- アニーリング法における温度$t$と同様
- アニーリング法ではステップ 2-3 で、確率を表す指数関数の計算と乱数の生成を行う必要がある。しかし、閾値受理法ではそれがない
- しかし、アニーリング法の指数関数の計算は高速化が可能なことが分かってしまったので、メリットとしては小さくなってしまった
- というかこれだったらアニーリング法でいい、みたいな結論になりがち
- 解の精度がアニーリング法に比べてそこまで悪いわけではない(悪くはある)
	- 簡単なルールでアルゴリズムを作っても、似た性能が得られるところに面白味がある

### 大洪水報

- 水位$\omega$を使う
- $\omega$は探索の初めには十分大きい値にしておく
- 反復ごとに新たに採用された$x$の評価値と現在の$\omega$の値の間の適当な値に更新することで徐々に小さくしていく
- 枠組み
	1.  初期解$x$を生成する。また、初期推移を$\omega:=\tilde{f}(x)$と定める
	1.  $N(x)$内の解を一つ選び$x'$とする
	1.  $\tilde{f}(x')\leq\omega$ならば$x:=x'$(解$x'$を受理)し、さら水位を$\omega:=\omega-\Delta_\omega$に下げる($\tilde{f}(x')>\omega$ならば何もしない)
	1.  終了条件が満たされれば暫定解を出力して探索終了。そうでなければステップ 2 へ戻る
- つまりは、探索が進んでいくごとに改悪解への移動を禁止するアニーリング法
- ステップ 3 の$\Delta_\omega$は定数にしてもよいが、以下のようなものも考えられる
	- $\Delta_\omega := \alpha(\omega - \tilde{f}(x'))$
	- $\Delta_\omega := \Beta\tilde{f}(x')$
- 2 つのうち大きい方を$\Delta_\omega$とする方法もある
- $\omega<\tilde{f}(x')$となってしまうと、解の移動を行う条件が単純局所探索法より厳しくなってしまう
	- 平均的には$\Delta_\omega \ll \omega - \tilde{f}(x')$が成り立つように注意してパラメータを設定する必要がある
		- 右辺は 0 に成りえるので常に成立させる必要はない

## タブー探索

- 近傍$N(x)$全体の中で、$x$以外の最良の解を次の解として選ぶ
	- このルールにより、現在の解が局所最適解であっても他の解への移動が強制される
- サイクリング
	- 現在の解$x$が局所最適解である場合、$x$から他の解$x'\in N(x)$に移動した後に、もう一度移動すると$x$に戻ってくることが多い
	- そうでなくとも、いくつか経由した後に元に戻ってくることをサイクリングという
- タブーリスト/短期メモリ
	- サイクリングを避けるために用意される解集合
	- この解集合への移動を禁止される
- 長期メモリ
	- 探索解の特徴を長期的にわたり記憶したもの
		- 特定の変数を変更した頻度や、特定の変数がある値を取り続けた期間の長さなど
	- 未探索の領域へ探索を方向付けるため
- 短期メモリと長期メモリを両方用いて、探索の集中化と多様化を組み合わせるのが良い
- 適応メモリ戦略
	- 長期メモリに基づく様々な手法のこと

### タブー探索法の基本構成

- タブーリスト$T$を用意し、$N(x) - (\{x\}\cup U)$内の最良の解へ移動することが基本動作
- 枠組み

	1.  初期解$x$を生成する。タブーリスト$T$を初期化する
	1.  $N(x) - (\{x\}\cup U)$の中で最も望ましいと考えられる解$x'$を見つけ、$x:=x'$とする
	1.  終了条件が満たされれば暫定解を出力して探索終了。そうでなければ、タブーリスト$T$を更新してステップ 2 へ

- タブーリスト$T$は最近探索した解が含まれるように動的に制御される
- ステップ 3 の終了条件は以下のようなものが用いられることが多い
	- あらかじめ定められた反復回数で終了する
	- あらかじめ定められた反復回数の間に暫定解の更新がなければ終了

### タブーリストの構成

- 最近探索した解を直接記憶するのが一つのタブーリスト作成方法
	- サイクリングを防ぐのに十分な効果が得られない場合がある
- なので、通常は解をそのまま記憶しない
- 最近の近傍操作において移動の前後で値の変わった変数を記憶しておき、以下のようなルールが用いられる
	- $T$内の変数値を変更することを禁止する
	- $T$内の変数の値が変更前の値に戻ることを禁止する
- 属性
	- ルールに利用される移動の特徴のこと
- タブー期間
	- 禁止規則を探索の間、常に保持し続けると、移動できる解がいずれなくなってしまう
	- なので、タブー期間$t_{tabu}$を用意する
	- 一つの属性がタブーリストに入ってから$t_{tabu}$回反復したときに、その属性をタブーリストから除くようにする
- 例) 最大充足化問題で 1 反転近傍$N_{1-flip}$を用いた場合の規則
	1.  移動の前と後で変数$v_i$の 0-1 割当が変更されたとき、添字$i$をタブーリストに記憶する。タブーリストに含まれる全ての添え字$i$について、$v_i$の値の変更を禁止する - この場合、属性は各添字
- 例) 最大充足化問題で 2 反転近傍$N_{2-flip}$を用いた場合の規則
	1.  移動の前後で 0-1 割当が変更された変数の添字全てをタブーリストに記憶する。タブーリストに含まれる全ての添字$i$について$v_i$の値の変更を禁止する - $v_i$と$v_j$の値が変更されたときは$i$と$j$をタブーリストに追加し、$v_i$への移動も$v_j$への移動も禁止する
	1.  移動の前後で 0-1 割当が変更された変数の添字の集合をタブーリストに記憶する。タブーリストに含まれる添字集合に対し、0-1 割当変更される変数の添字集合が一致する移動を禁止する - $v_i$と$v_j$の値が変更されたときは$\{i,j\}$をタブーリストに追加し、$v_i$と$v_j$の移動が同時に起きる時、移動を禁止する
	- この場合、上の規則の方が制限が大きい。
	- 下の規則のようなペアを対象とするルールの方が性能が良い場合が多い
		- 上の規則だと制限がきつすぎるため
- 例) 1 機械スケジューリング問題や巡回セールスマン問題において、順列に対する交換近傍$N_{swap}$を用いた場合の規則
	1.  移動の前後で順列$\sigma$の$k$番目と$l$番目が交換されたとする。このとき、添字の要素のペア$(k,\sigma(k))$と$(l,\sigma(l))$をタブーリストに記憶する。そして、タブーリストにペア$(k,i)$が存在するとき、順列の$k$番目の要素が$i$となる移動を禁止する - 一つの添え字$k$に対して、$\sigma(k)$のとりえる値が多数あるため、このような規則が考えられる
- 例) 巡回セールスマン問題において 2-opt 近傍$N_{2-opt}$を用いた場合
	1.  移動によって買いに加えられた枝をタブーリストに記憶する。そして、タブーリストに入っている枝を解から除くような移動を禁止する
	1.  移動によって買いに加えられた枝をタブーリストに記憶する。そして、タブーリストに入っている枝を解に加えるような移動を禁止する - 移動によって枝が解に加えられることと解から除かれることが対称でない性質から以上のような規則が考えられる
- タイプの異なる禁止規則が異なる考えられるとき
	- それぞれのタブーリストを準備し、いずれかで禁止される移動を禁止することも可能
- 属性のリストをそのまま保持し、解を探索するたびにそのリストを操作するのは効率が悪い
	- そのため、次のような方法がとられる
		- 大きさ$n$の配列$\mu=(\mu_1,\cdots,\mu_n)$を用意し、全ての$i$に対し$\mu_i=-\infty$と初期化する
		- 探索が始まった時点からの反復回数$c$をカウントしておく
		- 反復回数$c$における解の移動の際に変数$v_i$の値が変更されたとき、$\mu_i=c$に更新する
	- 以上のようにすると、各反復において、変数$v_i$の値を変更する移動が禁止されているかどうかを調べるには以下が成立すれば禁止されていると判定すればよい
		- この判定は$O(1)$でできる

$$
\begin{aligned}
	(そのときの反復回数c) -\mu_i \leq t_{tabu}
\end{aligned}
$$

### タブー探索の移動戦略

- タブー探索のステップ 2 の移動法の中でもっとも基本的なものは以下である
	- $N(x)-(\{x\}\cup U)$の中で評価値$\tilde{f}$が最良の解$x'$を見つけ、$x:=x'$とする

工夫の一つに以下のようなものがある

- 特別選択基準
	- タブーリストによって禁止されている解$x'\in N(x) \cup T$ でも次のような判断がされる場合にはタブーを犯して解への移動を実行するというもの
		- 解$x'$を採択してもサイクリングが起こらない
		- 解$x'$を採択することに十分意味がある
	- よく利用されるのは
		- $x'$は実行可能解かつ目的関数の値$f(x')$が暫定値を更新する
		- 評価関数の値$\tilde{f}(x')$がこれまで探索した度の解よりも小さい

一回の移動にかかる時間短縮の工夫

- 近傍を全て調べたのち最良解を得る場合
	- 近傍全探索は当然時間がかかるので工夫が重要
	- 近傍が大きい場合や近傍内の解のコストを計算するのに時間がかかる(O(1)で計算できない場合)は特に注意
- 近傍を全部は調べない場合 候補リスト戦略
	- $N(x) \setminus (\{x\}\cup T)$全体ではなく、その中の見込みがありそうな候補回に探索を絞る
- 限定選択戦略
	- 候補リスト戦略の一つ
	- パラメータとして次を用意する
		- $\alpha_{min},\alpha_{max},\alpha_{plus},\beta$
		- $0 < \alpha_{min}<\alpha_{max}<1, 0<\alpha_{plus}<1,0\leq\beta$
	- $x$の近傍内の解をランダムな順序で調べていき$\tilde{f}(x')-\tilde{f}(x)\leq\beta$を満たす解$x'$が初めて見つかった時点から、$\alpha_{plus}\cdot|N(x)|$個の解を探索し、最良の解に移動する
		- 探索によって調べた解の個数が$\alpha_{min}\cdot|N(x)|$に満たない場合はその個数に達するまで探索を続ける
		- 探索によって調べた解の個数が$\alpha_{max}\cdot|N(x)|$に達した場合は探索を打ち切る

### 適応メモリ戦略

過去の探索で得られた情報をいろいろな形で保存して起き、将来の探索に利用する手法の総称

- 長期メモリ
	- 探索の履歴情報のこと
	- 頻度メモリ
		- ある変数が解の移動において変更された頻度や、ある変数が特定の値をとっていた頻度を保存しておく
	- タブー探索の最中に利用したり、タブー探索が終了した後に利用したりする
	- 利用法 1
		- ある特定の変数の値が過去の探索で頻繁に変更されている場合にその変数を変更することにペナルティを与える
			- 長い周期でのサイクリングが起こっていると判断する
	- 利用法 2
		- 初期解をランダム/欲張り法で生成する
		- その際、次のような場合には、そのような割当が選ばれやすく(選ばれにくく)なるように確率に傾斜をかけたり、局所評価に変更を加える
			- これまでの探索で、ある変数が特定の値をとっていた時の解の平均精度が高い(低い)と判断された場合
			- これまでの探索で、ある変数が特定の値をとっていた期間が短い(長い)と判断された場合
	- 利用法1は多様化を目的としている
		- 通常、解の評価値にそのような変数のペナルティ項を重み付きで加えることで実現される
		- ペナルティが大きすぎると、良い解を探索する能力が低くなるので注意
		- ペナルティを小さくしたり、探索の多様化が必要と思われるときのみにペナルティ校を加えるなどの方法がとられる
	- 利用法2は、探索の集中化と多様化の両方に利用できる

